#!/usr/bin/env python3

"""mbc-prime
Find group-specific primer binding sites for amplicon metabarcoding

Usage:
  mbc-prime [options] -t INT <msa.fa>

Options:
  -t --target-seqs INT    number of target sequences (from top of alignment)
  -l --primer-length INT  primer length [default: 20]
  -s --score NUM          minimum score for both conservation and discrimination
                          [default: 0.5]
  -v --verbose            print verbose information, such as partial alignments
                          for each primer locus

  -b --beta NUM           Use F-score instead of Matthews correlation coefficient.
                          Use `-b=1` for regular F-score/F1. Other values for
                          F-beta scoring emphazising either False Positives or
                          True Negative. [default: -1]
  -r --reverse            Shifts the window where conservation is calculated to a window for a reverse primer
"""

import sys
import numpy as np
from math import sqrt
from statistics import mean
from statistics import median 
from collections import Counter
from collections import defaultdict 
from Bio.Seq import Seq
from Bio import AlignIO
from Bio.Align import MultipleSeqAlignment
from Bio.Align.AlignInfo import SummaryInfo
from docopt import docopt
import functools
import edlib

import logging

logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s %(asctime)s] %(message)s",
    datefmt="%Y-%m-%dT%H:%M:%SZ")

def main():

    if len(sys.argv) == 1:
        sys.argv.append('-h')

    opt = docopt(__doc__, version='mbc-prime v0.4.0', options_first=True)
    logging.info(opt)
    min_score = float(opt['--score'])
    primer_length = int(opt['--primer-length'])
    x = int(opt['--target-seqs'])
    beta = float(opt['--beta'])
    reverse = opt['--reverse']
    max_gap_frac = .1

    
    # read msa
    logging.info("Importing MSA")
    msa = AlignIO.read(opt['<msa.fa>'], "fasta")
    n_cols_raw = msa.get_alignment_length()

    # trim gap cols (TODO)
    logging.info("Trimming and masking gaps")
    msa = trim_msa(msa, max_gap_frac = max_gap_frac)
    msa = mask_term_gaps(msa) # replace term gaps with ?
    n_cols = msa.get_alignment_length()

    with open(opt['<msa.fa>'] + "trimmed", "w") as handle:
        AlignIO.write(msa, handle, "fasta")

    logging.info(f"• trimmed from {n_cols_raw} to {n_cols} informative columns (<{max_gap_frac * 100}% gaps)")

    # DEPRECATED: Brute-forcing alignments seems even better
    # get contrast + conserve score for each col to prefilter promising loci
    # logging.info("Scoring for contrast and conservation")
    # col_scores = [score_column(msa[:x, i], msa[x:, i], beta) for i in range(n_cols)]
    # win_conserve = conserve_window([c['conserve_score'] for c in col_scores], primer_length)
    # win_contrast = contrast_window([c['contrast_score'] for c in col_scores], primer_length, min_score*.5)

    # win_top = []
    # for i,(s,t) in enumerate(zip(win_conserve, win_contrast)):
    #     if s > min_score and t['t'] > min_score:
    #         t['i'] = i
    #         win_top.append(t)
    # logging.info(f"• found {len(win_top)} high-scoring candidate loci")
            
    # compute edit distances
    logging.info(f"Computing distances for candidate loci")
    win_dist = block_dist(msa, x, primer_length)

    # for i,_ in enumerate(win_top):
    #     if i%3:
    #         continue
    #     a = win_dist[win_top[i]['i']]
    ii = -2
    g = 0

    print('group', 'pos', 'score', 'A: 0/1/2/3/4+ mm | unaligned',
          'B: 0/1/2/3/4+ mm | unaligned', 'primer A', 'closest B',
          'A-B-matched', 'A-aligned', 'B-aligned', sep = "\t")
    for i,_ in enumerate(win_dist):

        a = win_dist[i]
        a_sum = sum([a[i] for i in ['a0','a1','a2', 'a3', 'a-1']])
        a_frc = [round(a[i]/a_sum, 2) for i in ['a0','a1','a2', 'a3', 'a-1']]
        b_sum = sum([a[i] for i in ['b0','b1','b2', 'b3', 'b-1']])
        b_frc = [round(a[i]/b_sum, 2) for i in ['b0','b1','b2','b3', 'b-1']]
        ab_score = round(sum(np.subtract(
            np.cumsum(a_frc[0:2]), np.cumsum(b_frc[0:2])))/2, 2)
        #t_fwd = sum([j/primer_length if t > 0 else 0 for j,t in enumerate(win_contrast[i]['t_raw'])])
        #t_rev = sum([j/primer_length if t > 0 else 0 for j,t in enumerate(win_contrast[i]['t_raw'][::-1])])
        
        if ab_score < min_score:
            continue
        if ii+1 != i:
            g+=1
        ii = i

        #print(win_top[i])
        # print(round(win_conserve[i], 2), round(win_contrast[i]['t']/2, 2),
        #       sep="\t", end="\t")
        print(g, i+1, ab_score, a_frc, b_frc, a["a_rep"], a["matched_aligned"],
              a["target_aligned"], a["query_aligned"], _, sep="\t")
    sys.exit()
        
    # maximize left-/rightness of contrast columns


    print(f"Found {len(contrasts)} high-scoring loci")

def trim_msa(msa, max_gap_frac):
    n_cols = msa.get_alignment_length()
    max_gaps = len(msa) * max_gap_frac
    keep_i = []
    for i in range(n_cols):
        if msa[:, i].count("-") <= max_gaps:
            keep_i.append(i)

    # # extract and merge columns (slower than per seq below)
    # keep_cols = [msa[:,i:i+1] for i in keep_i]
    # re = functools.reduce(lambda a, b: a+b, keep_cols)
    # return(re)

    # extract non-gap slices per seq and build new MSA
    re = []
    for r in msa:
        r.seq = Seq("".join([str(r.seq)[i] for i in keep_i]))
        re.append(r)
    return(MultipleSeqAlignment(re))

def mask_term_gaps(msa, char="?"):
    n_cols = msa.get_alignment_length()
    re = []
    for r in msa:
        r.seq = r.seq.lstrip("-")
        n_pre = n_cols - len(r.seq)
        r.seq = "?" * n_pre + r.seq
        r.seq = r.seq.rstrip("-")
        n_suf = n_cols - len(r.seq)
        r.seq = r.seq + "?" * n_suf
        re.append(r)

    return(MultipleSeqAlignment(re))

def score_column(a, b, beta=-1):
    an = Counter(a)
    bn = Counter(b)
    (ac, TP) = an.most_common(1)[0]
    (bc, bnmc) = bn.most_common(1)[0]

    re = {
        'contrast_score': 0,
        'conserve_score': 0,
        'char_a': ac,
        'char_b': bc,
        'counts_a': an,
        'counts_b': bn
    }

    if ac == '-':
        return(re)

    tn = len(a) - an['-']
    FN = tn - TP
    FP = bn[ac]
    TN = len(b) - FP - bn['-']

    re['conserve_score'] = TP/tn
    if beta < 0:
        re['contrast_score'] = mcc(TP, TN, FP, FN)
    else:
        re['contrast_score'] = fbeta(TP, FN, FP, float(beta))

    return(re)
    
# https://en.wikipedia.org/wiki/Phi_coefficient
def mcc(TP, TN, FP, FN):
    denom = (TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)
    if denom == 0:
        denom = 1
    else:
        denom = sqrt(denom)
        
    return((TP * TN - FP * FN) / denom)

# https://en.wikipedia.org/wiki/F-score
def fbeta(TP, FN, FP, beta):
    b2 = beta**2
    return((1+b2)*TP / ((1+b2)*TP + b2*FN + FP))

# https://en.wikipedia.org/wiki/F-score
def fscore(TP, FN, FP):
    return(2*TP / (2*TP + FN + FP))

def fkoert(TP, FN, FP, penalty):
    return(2*TP / (2*TP + FN + penalty*FP)) #F = 2TP

def conserve_window(x, window_size):
    i = 0
    means = [] 

    while i < len(x) - window_size + 1: 
        window = x[i : i + window_size] 
        means.append(sum(window) / window_size)
        i += 1
        
    return(means)

def contrast_window(x, window_size, min_score):
    i = 0
    scores = list()
    
    while i < len(x) - window_size + 1: 
        w = x[i : i + window_size]
        w = top_q(w, min_score) # ignore lower scores
        scores.append({
            "t": sum(w),
            "t_raw": w,
        })
        i += 1

    return(scores)

def top_q(x, q=.5, low=0):
    r = [low if k < q else k for k in x]
    return(r)

# compute distance between each uniq seq of a msa block and the most abundant
# uniq seq in the block
def block_dist(msa, a_n, window_size, max_term_gap_frac = 0, term_gap_char = "?"):
    dists = []
    n_cols = msa.get_alignment_length() - window_size + 1
    max_term_gaps = window_size * max_term_gap_frac
    re_block = {
        'a0': 0, 'a1': 0, 'a2': 0, 'a3': 0, 'a-1': 0, 'a?': 0,
        'b0': 0, 'b1': 0, 'b2': 0, 'b3': 0, 'b-1': 0, 'b?': 0,
        "a_rep": None, "b_rep": None,
    }
    
    for i in range(n_cols):
        re = re_block.copy()
        a_msa = msa[:a_n, i:i+window_size]
        a_uniq = block_count(a_msa, max_term_gaps)

        # all seqs ignored in counter, e.g. too many term gaps
        if(len(a_uniq) == 0):
            dists.append(re)
            continue
        
        # compute a_rep and a_rep vs a dists
        a_rep, a_rep_n = a_uniq.most_common(1)[0]
        del a_uniq[a_rep]
        re['a_rep'] = a_rep
        re['a0'] = a_rep_n
        re.update(dist_uniq(a_uniq, a_rep, 'a'))

        # compute a_rep vs b dists
        b_msa = msa[a_n:, i:i+window_size]
        b_uniq = block_count(b_msa, max_term_gaps)
        b_rep = b_uniq.most_common(1)[0][0]
        re['b_rep'] = b_rep
        re.update(dist_uniq(b_uniq, a_rep, 'b'))

        # compute representative alignment
        ab_aln = edlib.align(a_rep, b_rep, task='path')
        ab_nice = edlib.getNiceAlignment(ab_aln, a_rep, b_rep)
        re.update(ab_nice)

        dists.append(re)

    return(dists)

def block_count(msa_block, max_term_gaps):
    block = [str(b.seq) for b in msa_block]
    # mask terminal gap seqs with '?'
    block = ['?' if max_term_gaps <  s.count('?') else s for s in block]
    # DEPRECATED - unwanted side effects
    # block = gap_trim(block)
    block_seqs = Counter(block)
    return(block_seqs)

def dist_uniq(block_uniq, ref, pre):
    re = defaultdict(int)
    if not len(block_uniq):
        return (re)

    re[pre + '?'] = block_uniq.pop('?', 0)
    if not len(block_uniq):
        return (re)

    seqs = list(block_uniq.keys())
    seq_counts = list(block_uniq.values())
    seq_dists = [edlib.align(ref, seq, k=3)["editDistance"] for seq in seqs]
    for k,v in zip(seq_dists, seq_counts):
        re[pre + str(k)] += v
    return(re)


if __name__ == "__main__":
    main()


#- DEPRECATED ------------------------------------------------------------
def contrast_window_weighted(x, window_size, reverse=False):
    i = 0
    scores = list()
    weights = [(window_size - j) / window_size for j in range(window_size)]
    if not reverse:
        weights.reverse()
    
    while i < len(x) - window_size + 1: 
        w = x[i : i + window_size]
        w = top_q(w) # ignore lower scores
        s = [w[j] * weights[j] for j,_ in enumerate(w)] # weight scores by position
        scores.append({
            "t": sum(s),
            "t_raw": list(filter(lambda x: x > 0 , w)),
            "t_wgt": list(filter(lambda x: x > 0 , s))
         })
        i += 1

    return(scores)

def contrast_msa(msa, x, primer_length, min_score, beta):

    n_cols = msa.get_alignment_length()

    # score each column
    col_scores = [score_column(msa[:x, i], msa[x:, i], beta) for i in range(n_cols)]

    # aggregate across windows
    win_conserve = conserve_window([c[3] for c in cols], primer_length)
    contrast_fwd = contrast_window([c[2] for c in cols], primer_length)
    contrast_rev = contrast_window([c[2] for c in cols], primer_length, reverse=True)
    # inefficient, could compute consense windows only as needed after filter
    consense = consense_window([(c[0], c[1]) for c in cols], primer_length)

    wins_fwd = []
    wins_rev = []
    # filter windows
    for i,s in enumerate(conserve):
        if s > min_score:
            
            if contrast_fwd[i]["t"] > min_score:
                wins_fwd.append({
                    "start": i,
                    "s": round(conserve[i], 2),
                    "diff": consense[i],
                    "t": round(contrast_fwd[i]["t"], 2),
                    "t_wgt": [round(x, 2) for x in contrast_fwd[i]["t_wgt"]],
                    "t_raw": [round(x, 2) for x in contrast_fwd[i]["t_raw"]]
                })
            if contrast_rev[i]["t"] > min_score:
                wins_rev.append({
                    "start": i,
                    "s": conserve[i],
                    "t": contrast_rev[i]["t"],
                    "diff_fwd": consense[i]
                })

    return(wins_fwd)

def gap_trim(seqs):
    seqs = [s.replace("-", "").replace("?", "") for s in seqs]
    return(seqs)

def consense_pair(a, b):
    if a == b:
        return "."
    return(a)

def consense_window(x, window_size):
    i = 0
    x = [consense_pair(a,b) for a,b in x]
    consensi = []
    
    while i < len(x) - window_size + 1: 
        consensi.append("".join(x[i : i + window_size]))
        i += 1

    return(consensi)
