#!/usr/bin/env python3

"""mbc-prime
Find group-specific primer binding sites for amplicon metabarcoding

Usage:
  mbc-prime [options] -t INT <msa.fa>

Options:
  -m --mismatches INT     target number of mismatches for sequences to exclude [default: 2]
  -t --target-seqs INT    number of target sequences (from top of alignment)
  -l --primer-length INT  primer length [default: 20]
  -s --score NUM          minimum score for both conservation and discrimination
                          [default: 0.5]
  -v --verbose            print verbose information, such as partial alignments
                          for each primer locus

  -b --beta NUM           Use F-score instead of Matthews correlation coefficient.
                          Use `-b=1` for regular F-score/F1. Other values for
                          F-beta scoring emphazising either False Positives or
                          True Negative. [default: -1]
  -r --reverse            Shifts the window where conservation is calculated to a window for a reverse primer
"""

import sys
import numpy as np
import re
import string
from math import sqrt
from statistics import mean
from statistics import median 
from collections import Counter
from collections import defaultdict 
from Bio.Seq import Seq
from Bio import AlignIO
from Bio.Align import MultipleSeqAlignment
from Bio.Align.AlignInfo import SummaryInfo
from docopt import docopt
import functools
import edlib

import logging

logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s %(asctime)s] %(message)s",
    datefmt="%Y-%m-%dT%H:%M:%SZ")

def main():

    if len(sys.argv) == 1:
        sys.argv.append('-h')

    opt = docopt(__doc__, version='mbc-prime v0.5.0', options_first=True)
    logging.info(opt)
    min_score = float(opt['--score'])
    primer_length = int(opt['--primer-length'])
    x = int(opt['--target-seqs'])
    beta = float(opt['--beta'])
    reverse = opt['--reverse']
    mm = int(opt['--mismatches'])
    min_canon_frac = .2
    max_ambig_frac = .2

    
    # read msa
    logging.info("Importing MSA")
    msa = AlignIO.read(opt['<msa.fa>'], "fasta")
    n_cols_raw = msa.get_alignment_length()

    # trim gap cols (TODO)
    logging.info("Trimming internal and masking terminal gaps")
    msa = trim_msa(msa, min_canon_frac = min_canon_frac)
    msa_orig_i = msa.column_annotations['orig_i']

    msa = mask_term_gaps(msa) # replace term gaps with ?
    n_cols = msa.get_alignment_length()

    with open(opt['<msa.fa>'] + "trimmed", "w") as handle:
        AlignIO.write(msa, handle, "fasta")

    logging.info(f"• trimmed from {n_cols_raw} to {n_cols} informative columns (<{(1-min_canon_frac) * 100}% gaps)")

    # compute edit distances
    logging.info(f"Computing distances for candidate loci")
    win_dist = block_dist(msa, x, primer_length)
    ii = -2
    g = 0
    
    # header
    print('group', 'pos', 'trimmed_pos', 'score', 'inc: 0,1,2,3,4+ mismatches',
          'exc: 0,1,2,3,4+ mismatches', 'primer forward', 'primer reverse',
          'inc-exc-matched', 'inc-aligned', 'exc-aligned', 'info', sep = "\t")
    for i,_ in enumerate(win_dist):

        a = win_dist[i]
        a_sum = sum([a[i] for i in ['a0','a1','a2', 'a3', 'a-1', 'a?']])
        a_frc = [round(a[i]/a_sum, 2) for i in ['a0','a1','a2', 'a3', 'a-1', 'a?']]
        b_sum = sum([a[i] for i in ['b0','b1','b2', 'b3', 'b-1', 'b?']])
        b_frc = [round(a[i]/b_sum, 2) for i in ['b0','b1','b2','b3', 'b-1', 'b?']]
        ab_score = round(sum(np.subtract(
            np.cumsum(a_frc[0:mm]), np.cumsum(b_frc[0:mm])))/mm, 2)
        # too many seqs with ambigious chars (term gaps, Ns, ..)
        if a_frc[5] > max_ambig_frac or b_frc[5] > max_ambig_frac:
            continue
        if ab_score < min_score:
            continue
        if ii+1 != i:
            g+=1
            print(f"# locus {g}")
        ii = i

        #print(win_top[i])
        # print(round(win_conserve[i], 2), round(win_contrast[i]['t']/2, 2),
        #       sep="\t", end="\t")
        print(g, msa_orig_i[i]+1, i+1, ab_score, a_frc[0:4], b_frc[0:4], a["a_rep"], rc(a["a_rep"]), a["matched_aligned"],
              a["target_aligned"], a["query_aligned"], _, sep="\t")
    sys.exit()
        
    # maximize left-/rightness of contrast columns


    print(f"Found {len(contrasts)} high-scoring loci")

def rc(x):
    x=x.translate(x.maketrans("atgcuATGCU", "tacgaTACGA"))
    return(x[::-1])
    
def trim_msa(msa, min_canon_frac):
    n_cols = msa.get_alignment_length()
    n_rows = len(msa)
    min_canon = round(n_rows * min_canon_frac)
    logging.info(f"• max gaps/ambigious per column: {n_rows - min_canon}")
    keep_i = []
    for i in range(n_cols):
        if canon(msa[:, i]) >= min_canon:
            keep_i.append(i)

    # # extract and merge columns (slower than per seq below)
    # keep_cols = [msa[:,i:i+1] for i in keep_i]
    # re = functools.reduce(lambda a, b: a+b, keep_cols)
    # return(re)

    # extract non-gap slices per seq and build new MSA
    re = []
    for r in msa:
        r.seq = Seq("".join([str(r.seq)[i] for i in keep_i]))
        re.append(r)
    re
        
    return(MultipleSeqAlignment(re, column_annotations={"orig_i": keep_i}))

def mask_term_gaps(msa, char="?"):
    n_cols = msa.get_alignment_length()
    re = []
    for r in msa:
        r.seq = r.seq.lstrip("-")
        n_pre = n_cols - len(r.seq)
        r.seq = "?" * n_pre + r.seq
        r.seq = r.seq.rstrip("-")
        n_suf = n_cols - len(r.seq)
        r.seq = r.seq + "?" * n_suf
        re.append(r)

    return(MultipleSeqAlignment(re))

def score_column(a, b, beta=-1):
    an = Counter(a)
    bn = Counter(b)
    (ac, TP) = an.most_common(1)[0]
    (bc, bnmc) = bn.most_common(1)[0]

    re = {
        'contrast_score': 0,
        'conserve_score': 0,
        'char_a': ac,
        'char_b': bc,
        'counts_a': an,
        'counts_b': bn
    }

    if ac == '-':
        return(re)

    tn = len(a) - an['-']
    FN = tn - TP
    FP = bn[ac]
    TN = len(b) - FP - bn['-']

    re['conserve_score'] = TP/tn
    if beta < 0:
        re['contrast_score'] = mcc(TP, TN, FP, FN)
    else:
        re['contrast_score'] = fbeta(TP, FN, FP, float(beta))

    return(re)
    
# https://en.wikipedia.org/wiki/Phi_coefficient
def mcc(TP, TN, FP, FN):
    denom = (TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)
    if denom == 0:
        denom = 1
    else:
        denom = sqrt(denom)
        
    return((TP * TN - FP * FN) / denom)

# https://en.wikipedia.org/wiki/F-score
def fbeta(TP, FN, FP, beta):
    b2 = beta**2
    return((1+b2)*TP / ((1+b2)*TP + b2*FN + FP))

# https://en.wikipedia.org/wiki/F-score
def fscore(TP, FN, FP):
    return(2*TP / (2*TP + FN + FP))

def fkoert(TP, FN, FP, penalty):
    return(2*TP / (2*TP + FN + penalty*FP)) #F = 2TP

def conserve_window(x, window_size):
    i = 0
    means = [] 

    while i < len(x) - window_size + 1: 
        window = x[i : i + window_size] 
        means.append(sum(window) / window_size)
        i += 1
        
    return(means)

def contrast_window(x, window_size, min_score):
    i = 0
    scores = list()
    
    while i < len(x) - window_size + 1: 
        w = x[i : i + window_size]
        w = top_q(w, min_score) # ignore lower scores
        scores.append({
            "t": sum(w),
            "t_raw": w,
        })
        i += 1

    return(scores)

def top_q(x, q=.5, low=0):
    r = [low if k < q else k for k in x]
    return(r)

# compute distance between each uniq seq of a msa block and the most abundant
# uniq seq in the block
def block_dist(msa, a_n, window_size):
    dists = []
    n_cols = msa.get_alignment_length() - window_size + 1
    re_block = {
        'a0': 0, 'a1': 0, 'a2': 0, 'a3': 0, 'a-1': 0, 'a?': 0,
        'b0': 0, 'b1': 0, 'b2': 0, 'b3': 0, 'b-1': 0, 'b?': 0,
        "a_rep": None, "b_rep": None,
    }
    
    for i in range(n_cols):
        re = re_block.copy()
        a_msa = msa[:a_n, i:i+window_size]
        a_uniq = block_count(a_msa)

        # term-gappy/ambigious sequences
        if "?" in a_uniq:
            re['a?'] = a_uniq["?"]
            del a_uniq["?"]

        # all seqs ignored in counter, e.g. too many term gaps
        if(len(a_uniq) == 0):
            dists.append(re)
            continue
        
        # compute a_rep and a_rep vs a dists
        a_rep, a_rep_n = a_uniq.most_common(1)[0]
        del a_uniq[a_rep]
        re['a_rep'] = a_rep
        re['a0'] = a_rep_n
        re.update(dist_uniq(a_uniq, a_rep, 'a'))

        # compute a_rep vs b dists
        b_msa = msa[a_n:, i:i+window_size]
        b_uniq = block_count(b_msa)

        # term-gappy/ambigious sequences
        if "?" in b_uniq:
            re['b?'] = b_uniq["?"]
            del b_uniq["?"]

        # all seqs ignored in counter, e.g. too many term gaps
        if(len(b_uniq) == 0):
            dists.append(re)
            continue

        b_rep = b_uniq.most_common(1)[0][0]
        re['b_rep'] = b_rep
        re.update(dist_uniq(b_uniq, a_rep, 'b'))

        # compute representative alignment
        ab_aln = edlib.align(a_rep, b_rep, task='path')
        ab_nice = edlib.getNiceAlignment(ab_aln, a_rep, b_rep)
        re.update(ab_nice)

        dists.append(re)

    return(dists)

def canon(x, canon_chars = "[atgcuATGCU]"):
    return(len(re.findall(canon_chars, x)))

def ambig(x, canon_chars = "[^atgcuATGCU-]"):
    return(len(re.findall(canon_chars, x)))


def block_count(msa_block, max_ambig = 0):
    block = [str(b.seq) for b in msa_block]
    block = ['?' if ambig(s) > max_ambig else s for s in block]
    block_seqs = Counter(block)
    return(block_seqs)

def dist_uniq(block_uniq, ref, pre):
    re = defaultdict(int)
    if not len(block_uniq):
        return (re)

    re[pre + '?'] = block_uniq.pop('?', 0)
    if not len(block_uniq):
        return (re)

    seqs = list(block_uniq.keys())
    seq_counts = list(block_uniq.values())
    seq_dists = [edlib.align(ref, seq, k=3)["editDistance"] for seq in seqs]
    for k,v in zip(seq_dists, seq_counts):
        re[pre + str(k)] += v
    return(re)


if __name__ == "__main__":
    main()


#- DEPRECATED ------------------------------------------------------------
def contrast_window_weighted(x, window_size, reverse=False):
    i = 0
    scores = list()
    weights = [(window_size - j) / window_size for j in range(window_size)]
    if not reverse:
        weights.reverse()
    
    while i < len(x) - window_size + 1: 
        w = x[i : i + window_size]
        w = top_q(w) # ignore lower scores
        s = [w[j] * weights[j] for j,_ in enumerate(w)] # weight scores by position
        scores.append({
            "t": sum(s),
            "t_raw": list(filter(lambda x: x > 0 , w)),
            "t_wgt": list(filter(lambda x: x > 0 , s))
         })
        i += 1

    return(scores)

def contrast_msa(msa, x, primer_length, min_score, beta):

    n_cols = msa.get_alignment_length()

    # score each column
    col_scores = [score_column(msa[:x, i], msa[x:, i], beta) for i in range(n_cols)]

    # aggregate across windows
    win_conserve = conserve_window([c[3] for c in cols], primer_length)
    contrast_fwd = contrast_window([c[2] for c in cols], primer_length)
    contrast_rev = contrast_window([c[2] for c in cols], primer_length, reverse=True)
    # inefficient, could compute consense windows only as needed after filter
    consense = consense_window([(c[0], c[1]) for c in cols], primer_length)

    wins_fwd = []
    wins_rev = []
    # filter windows
    for i,s in enumerate(conserve):
        if s > min_score:
            
            if contrast_fwd[i]["t"] > min_score:
                wins_fwd.append({
                    "start": i,
                    "s": round(conserve[i], 2),
                    "diff": consense[i],
                    "t": round(contrast_fwd[i]["t"], 2),
                    "t_wgt": [round(x, 2) for x in contrast_fwd[i]["t_wgt"]],
                    "t_raw": [round(x, 2) for x in contrast_fwd[i]["t_raw"]]
                })
            if contrast_rev[i]["t"] > min_score:
                wins_rev.append({
                    "start": i,
                    "s": conserve[i],
                    "t": contrast_rev[i]["t"],
                    "diff_fwd": consense[i]
                })

    return(wins_fwd)

def gap_trim(seqs):
    seqs = [s.replace("-", "").replace("?", "") for s in seqs]
    return(seqs)

def consense_pair(a, b):
    if a == b:
        return "."
    return(a)

def consense_window(x, window_size):
    i = 0
    x = [consense_pair(a,b) for a,b in x]
    consensi = []
    
    while i < len(x) - window_size + 1: 
        consensi.append("".join(x[i : i + window_size]))
        i += 1

    return(consensi)
