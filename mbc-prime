#!/usr/bin/env python3

"""mbc-prime - find group-specific primer binding sites for amplicon metabarcoding

Citation:
• Ting He, Koert Jansonius, Bahar Sevgin, Thomas Hackl, Kristina Haslinger; ...
• Martin Šošić, Mile Šikić; Edlib: a C/C ++ library for fast, exact sequence
  alignment using edit distance. Bioinformatics 2017 btw753. doi:
  10.1093/bioinformatics/btw753

Usage:
  mbc-prime [options] -t INT <msa.fa>

Options:
  -l --primer-length INT  primer length [default: 20]
  -t --target-seqs INT    number of target sequences (from top of alignment)
  -s --min-score NUM      minimum score to report a locus [default: 0.5]
  -m --mismatches INT     target number of mismatches for sequences to exclude
                          [default: 2]
  --min-canon-col NUM     trim columns with less than this fraction of non-gap/
                          ambiguous bases (not atgcuATGCU) [default: 0.2]
  --max-ambig-win NUM     ignore primer windows with more than this many ambigious
                          bases [default: 0.2]
  -v --verbose            print verbose information, such as partial alignments
                          for each primer locus

Known limitations:
• If the primer regions itself contains gaps, which could correspond to bases
  not present in exclusion set, and could be useful in constructing discriminative
  primers, these gaps are reported as is and the primer window is not extended to
  include the adjacant bases, which would be necessary to produce a complete
  primer
• Primer candidates are not checked for potential hits to other locations in the
  provided sequence set

"""

import sys
import numpy as np
import re
import string
from math import sqrt
from statistics import mean
from statistics import median 
from collections import Counter
from collections import defaultdict 
from Bio.Seq import Seq
from Bio import AlignIO
from Bio.Align import MultipleSeqAlignment
from Bio.Align.AlignInfo import SummaryInfo
from docopt import docopt
import functools
import edlib

import logging


def main():

    if len(sys.argv) == 1:
        sys.argv.append('-h')

    opt = docopt(__doc__, version='mbc-prime v0.6.0', options_first=True)
    
    logging.basicConfig(
        level=logging.DEBUG if opt['--verbose'] else logging.INFO,
        format="[%(levelname)s %(asctime)s] %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%SZ")

    logging.debug(opt)
    primer_length = int(opt['--primer-length'])
    x = int(opt['--target-seqs'])
    mm = int(opt['--mismatches'])
    min_score = float(opt['--min-score'])
    min_canon_frac = float(opt['--min-canon-col'])
    max_ambig_frac = float(opt['--max-ambig-win'])
    
    # read msa
    logging.info("Importing MSA")
    msa = AlignIO.read(opt['<msa.fa>'], "fasta")
    n_cols_raw = msa.get_alignment_length()

    # trim gap cols (TODO)
    logging.info("Trimming internal and masking terminal gaps")
    msa = trim_msa(msa, min_canon_frac = min_canon_frac)
    msa_orig_i = msa.column_annotations['orig_i']

    msa = mask_term_gaps(msa) # replace term gaps with ?
    n_cols = msa.get_alignment_length()
    msa_trimmed_file = opt['<msa.fa>'] + ".trimmed"

    
    logging.info(f"• trimmed from {n_cols_raw} to {n_cols} informative columns (<{(1-min_canon_frac) * 100}% gaps)")

    with open(msa_trimmed_file, "w") as handle:
        AlignIO.write(msa, handle, "fasta")
    logging.info(f"• wrote trimmed msa to '{msa_trimmed_file}'")

    # compute edit distances
    logging.info(f"Computing distances for candidate loci")
    win_dist = block_dist(msa, x, primer_length)
    ii = -2
    g = 0
    
    # header
    print('group', 'pos', 'trimmed_pos', 'score', 'inc: 0,1,2,3,4+ mismatches',
          'exc: 0,1,2,3,4+ mismatches', 'primer forward', 'primer reverse',
          'inc-exc-matched', 'inc-aligned', 'exc-aligned', 'info', sep = "\t")
    for i,_ in enumerate(win_dist):

        a = win_dist[i]
        a_sum = sum([a[i] for i in ['a0','a1','a2', 'a3', 'a-1', 'a?']])
        a_frc = [a[i]/a_sum for i in ['a0','a1','a2', 'a3', 'a-1', 'a?']]
        a_cum = np.cumsum(a_frc)
        b_sum = sum([a[i] for i in ['b0','b1','b2', 'b3', 'b-1', 'b?']])
        b_frc = [a[i]/b_sum for i in ['b0','b1','b2','b3', 'b-1', 'b?']]
        b_cum = np.cumsum(b_frc)
        ab_score = round(sum(np.subtract(
            np.cumsum(a_frc[0:mm]), np.cumsum(b_frc[0:mm])))/mm, 2)

        # too many gaps in primer
        if a["a_rep"].count('-') > 3:
            continue
        # too many seqs with ambigious chars (term gaps, Ns, ..)
        if a_frc[5] > max_ambig_frac or b_frc[5] > max_ambig_frac:
            continue
        if ab_score < min_score:
            continue
        if ii+1 != i:
            g+=1
            print(f"# locus {g}")
        ii = i

        #print(win_top[i])
        # print(round(win_conserve[i], 2), round(win_contrast[i]['t']/2, 2),
        #       sep="\t", end="\t")
        print(g, msa_orig_i[i]+1, i+1, ab_score, rl(a_cum[0:5], 2), rl(b_cum[0:5], 2),
              a["a_rep"], rc(a["a_rep"]), a["matched_aligned"],
              a["target_aligned"], a["query_aligned"], _, sep="\t")

    logging.info(f"Found {g} above-threshold candidate loci for primer design")

def rc(x):
    x=x.translate(x.maketrans("atgcuATGCU", "tacgaTACGA"))
    return(x[::-1])

def rl(l, digits=0):
    return([round(x.item(), digits) for x in l])
    
def trim_msa(msa, min_canon_frac):
    n_cols = msa.get_alignment_length()
    n_rows = len(msa)
    min_canon = round(n_rows * min_canon_frac)
    logging.info(f"• max gaps/ambigious per column: {n_rows - min_canon}")
    keep_i = []
    for i in range(n_cols):
        if canon(msa[:, i]) >= min_canon:
            keep_i.append(i)

    # extract non-gap slices per seq and build new MSA
    re = []
    for r in msa:
        r.seq = Seq("".join([str(r.seq)[i] for i in keep_i]))
        re.append(r)
    re
        
    return(MultipleSeqAlignment(re, column_annotations={"orig_i": keep_i}))

def mask_term_gaps(msa, char="?"):
    n_cols = msa.get_alignment_length()
    re = []
    for r in msa:
        r.seq = r.seq.lstrip("-")
        n_pre = n_cols - len(r.seq)
        r.seq = "?" * n_pre + r.seq
        r.seq = r.seq.rstrip("-")
        n_suf = n_cols - len(r.seq)
        r.seq = r.seq + "?" * n_suf
        re.append(r)

    return(MultipleSeqAlignment(re))

    

# compute distance between each uniq seq of a msa block and the most abundant
# uniq seq in the block
def block_dist(msa, a_n, window_size):
    dists = []
    n_cols = msa.get_alignment_length() - window_size + 1
    re_block = {
        'a0': 0, 'a1': 0, 'a2': 0, 'a3': 0, 'a-1': 0, 'a?': 0,
        'b0': 0, 'b1': 0, 'b2': 0, 'b3': 0, 'b-1': 0, 'b?': 0,
        "a_rep": None, "b_rep": None,
    }
    
    for i in range(n_cols):
        re = re_block.copy()
        a_msa = msa[:a_n, i:i+window_size]
        a_uniq = block_count(a_msa)

        # term-gappy/ambigious sequences
        if "?" in a_uniq:
            re['a?'] = a_uniq["?"]
            del a_uniq["?"]

        # all seqs ignored in counter, e.g. too many term gaps
        if(len(a_uniq) == 0):
            dists.append(re)
            continue
        
        # compute a_rep and a_rep vs a dists
        a_rep, a_rep_n = a_uniq.most_common(1)[0]
        del a_uniq[a_rep]
        re['a_rep'] = a_rep
        re['a0'] = a_rep_n
        re.update(dist_uniq(a_uniq, a_rep, 'a'))

        # compute a_rep vs b dists
        b_msa = msa[a_n:, i:i+window_size]
        b_uniq = block_count(b_msa)

        # term-gappy/ambigious sequences
        if "?" in b_uniq:
            re['b?'] = b_uniq["?"]
            del b_uniq["?"]

        # all seqs ignored in counter, e.g. too many term gaps
        if(len(b_uniq) == 0):
            dists.append(re)
            continue

        b_rep = b_uniq.most_common(1)[0][0]
        re['b_rep'] = b_rep
        re.update(dist_uniq(b_uniq, a_rep, 'b'))

        # compute representative alignment
        ab_aln = edlib.align(a_rep, b_rep, task='path')
        ab_nice = edlib.getNiceAlignment(ab_aln, a_rep, b_rep)
        re.update(ab_nice)

        dists.append(re)

    return(dists)

def canon(x, canon_chars = "[atgcuATGCU]"):
    return(len(re.findall(canon_chars, x)))

def ambig(x, canon_chars = "[^atgcuATGCU-]"):
    return(len(re.findall(canon_chars, x)))

def block_count(msa_block, max_ambig = 0):
    block = [str(b.seq) for b in msa_block]
    block = ['?' if ambig(s) > max_ambig else s for s in block]
    block_seqs = Counter(block)
    return(block_seqs)

def dist_uniq(block_uniq, ref, pre):
    re = defaultdict(int)
    if not len(block_uniq):
        return (re)

    re[pre + '?'] = block_uniq.pop('?', 0)
    if not len(block_uniq):
        return (re)

    seqs = list(block_uniq.keys())
    seq_counts = list(block_uniq.values())
    seq_dists = [edlib.align(ref, seq, k=3)["editDistance"] for seq in seqs]
    for k,v in zip(seq_dists, seq_counts):
        re[pre + str(k)] += v
    return(re)


if __name__ == "__main__":
    main()
